{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 15:03:10.769887: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-22 15:03:10.769931: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from os import name\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Concatenate, BatchNormalization, Conv2DTranspose, Flatten, PReLU, Reshape, Dropout, AveragePooling2D, Add, Lambda, Layer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import MD_AE_model as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from :./PIV4_downsampled_by8.h5\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "data_file = './PIV4_downsampled_by8.h5'\n",
    "Ntrain = 10 # snapshots for training\n",
    "Nval = 600 # sanpshots for validation\n",
    "Ntest = 600\n",
    "\n",
    "# Boolean \n",
    "LATENT_STATE = True # save latent state\n",
    "SHUFFLE = True # shuffle before splitting into sets, test set is extracted before shuffling\n",
    "REMOVE_MEAN = True # train on fluctuating velocity\n",
    "\n",
    "## ae configuration\n",
    "lmb = 0.0 #1e-05 #regulariser\n",
    "drop_rate = 0.2\n",
    "features_layers = [32, 64, 128]\n",
    "# latent_dim = 10\n",
    "batch_size = 5\n",
    "act_fct = 'tanh'\n",
    "resize_meth = 'bilinear'\n",
    "filter_window= (3,3)\n",
    "batch_norm = False\n",
    "\n",
    "Nz = 24 # grid size\n",
    "Ny = 21\n",
    "Nu = 2\n",
    "Nt = 2732 # number of snapshots available\n",
    "D = 196.5 # mm diameter of bluff body\n",
    "U_inf = 15 # m/s freestream velocity\n",
    "f_piv = 720.0 # Hz PIV sampling frequency  \n",
    "dt = 1.0/f_piv \n",
    "\n",
    "print('Reading dataset from :' + data_file)\n",
    "hf = h5py.File(data_file,'r')\n",
    "\n",
    "z = np.array(hf.get('z'))\n",
    "y = np.array(hf.get('y'))\n",
    "u_all = np.zeros((Nt,Nz,Ny,Nu))\n",
    "u_all[:,:,:,0] = np.array(hf.get('vy'))\n",
    "if Nu==2:\n",
    "    u_all[:,:,:,1] = np.array(hf.get('vz'))\n",
    "u_all = np.transpose(u_all,[0,2,1,3]) # shape of u_all = (Nt,Ny,Nz,Nu)\n",
    "hf.close()\n",
    "\n",
    "u_all = u_all[:,:,:,:].astype('float32')\n",
    "\n",
    "# remove mean for modes\n",
    "if REMOVE_MEAN:\n",
    "    u_mean_all = np.mean(u_all,axis=0) # time averaged, (Ny,Nz,Nu)\n",
    "    u_all = u_all - u_mean_all\n",
    "\n",
    "\n",
    "if SHUFFLE:\n",
    "    # temp_list = list(u_all)\n",
    "    # np.random.shuffle(temp_list) # this shuffles the first axis\n",
    "    # u_all = np.array(temp_list)\n",
    "\n",
    "    idx_test = np.random.randint(0,Nt-Ntest)\n",
    "    u_test = u_all[idx_test:idx_test+Ntest,:,:,:].astype('float32') # test set needs to be in order and has continuous snapshots\n",
    "    u_all = np.delete(u_all,np.s_[idx_test:idx_test+Ntest],0) # remove the test set from available samples\n",
    "    idx_shuffle = np.arange(Nt-Ntest) # use idx_shuffle to shuffle the rest of samples before taking a validation set\n",
    "    np.random.shuffle(idx_shuffle)\n",
    "    idx_unshuffle = np.argsort(idx_shuffle) # use idx_unshuffle to unshuffle the data\n",
    "    u_all = u_all[idx_shuffle,:,:,:]\n",
    "    u_train = u_all[0:Ntrain,:,:,:].astype('float32')\n",
    "    u_val = u_all[Ntrain:Ntrain+Nval,:,:,:].astype('float32')\n",
    "    u_all = np.vstack((u_train,u_val,u_test))\n",
    "else:\n",
    "    u_train = u_all[0:Ntrain,:,:,:].astype('float32')\n",
    "    u_val = u_all[Ntrain:Ntrain+Nval,:,:,:].astype('float32')\n",
    "    u_test = u_all[Ntrain+Nval:Ntrain+Nval+Ntest,:,:,:].astype('float32')\n",
    "    u_all = u_all[0:Ntrain+Nval+Ntest,:,:,:].astype('float32') # u_all has shape (Ntrain+Nval+Ntest,Ny,Nz,Nu)\n",
    "\n",
    "\n",
    "u_all = np.reshape(u_all,(1,Ntrain+Nval+Ntest,Ny,Nz,Nu)) # new shape (1,Nval+Ntrain+Ntest,Ny,Nz,Nu)\n",
    "u_train = np.reshape(u_train,(1,Ntrain,Ny,Nz,Nu))\n",
    "u_val = np.reshape(u_val,(1,Nval,Ny,Nz,Nu))\n",
    "u_test = np.reshape(u_test,(1,Ntest,Ny,Nz,Nu))\n",
    "Nx = [Ny, Nz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 21, 24, 2)\n"
     ]
    }
   ],
   "source": [
    "u = u_train[0,:,:,:,:]\n",
    "print(u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 15:03:13.063178: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-22 15:03:13.063203: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-22 15:03:13.063221: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ic-5rpzl43): /proc/driver/nvidia/version does not exist\n",
      "2022-03-22 15:03:13.063448: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 21, 24, 2)]       0         \n",
      "                                                                 \n",
      " encoder (Encoder)           (None, 1)                 94113     \n",
      "                                                                 \n",
      " decoder (Decoder)           (None, 21, 24, 2)         95138     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 189,251\n",
      "Trainable params: 189,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 2.0114\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.9877\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "encoder1 = model.Encoder(Nx=Nx,Nu=Nu,features_layers=features_layers,latent_dim=1,filter_window=filter_window,act_fct=act_fct,batch_norm=batch_norm,drop_rate=drop_rate,lmb=lmb)\n",
    "layer_size = encoder1.get_layer_shape()\n",
    "\n",
    "input_img = [Input(shape=(Nx[0],Nx[1],Nu))]\n",
    "x = encoder1(input_img[0])\n",
    "print(len(input_img) != 1)\n",
    "x_final = model.Decoder(Nx,Nu,layer_size,features_layers=features_layers,latent_dim=1,filter_window=filter_window,act_fct=act_fct,batch_norm=batch_norm,drop_rate=drop_rate,lmb=lmb)(x)\n",
    "mdl1 = Model(input_img,x_final)\n",
    "print(mdl1.summary())\n",
    "mdl1.compile(optimizer=Adam(learning_rate=0.001),loss='mse')\n",
    "mdl1.fit([u],u,epochs=2,batch_size=batch_size)\n",
    "z1 = encoder1.predict(u)\n",
    "print(z1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 21, 24, 2) dtype=float32 (created by layer 'input_4')>, <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_5')>]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "input_img = input_img = [Input(shape=(Nx[0],Nx[1],Nu))]\n",
    "input_img.extend([Input(shape=1)])\n",
    "print(input_img) \n",
    "print(len(input_img) != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<class 'list'>\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='stack/concat:0', description=\"created by layer 'stack'\")\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 21, 24, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " encoder_1 (Encoder)            (None, 1)            94113       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " stack (Concatenate)            (None, 2)            0           ['input_5[0][0]',                \n",
      "                                                                  'encoder_1[0][0]']              \n",
      "                                                                                                  \n",
      " decoder_1 (Decoder)            (None, 21, 24, 2)    96290       ['stack[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 190,403\n",
      "Trainable params: 190,403\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 1.9965\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.9305\n"
     ]
    }
   ],
   "source": [
    "encoder2 = model.Encoder(Nx=Nx,Nu=Nu,features_layers=features_layers,latent_dim=1,filter_window=filter_window,act_fct=act_fct,batch_norm=batch_norm,drop_rate=drop_rate,lmb=lmb)\n",
    "layer_size2 = encoder2.get_layer_shape()\n",
    "\n",
    "new_dim = np.sum([1],dtype=np.dtype('int'))+1\n",
    "print(new_dim)\n",
    "\n",
    "x = encoder2(input_img[0])\n",
    "new_x = input_img[1::]\n",
    "new_x.extend([x])\n",
    "print(type(new_x))\n",
    "x = Concatenate(name='stack')(new_x)\n",
    "print(x)\n",
    "\n",
    "x_final = model.Decoder(Nx,Nu,layer_size,features_layers=features_layers,latent_dim=new_dim,filter_window=filter_window,act_fct=act_fct,batch_norm=batch_norm,drop_rate=drop_rate,lmb=lmb)(x)\n",
    "mdl2 = Model(input_img,x_final)\n",
    "print(mdl2.summary())\n",
    "mdl2.compile(optimizer=Adam(learning_rate=0.001),loss='mse')\n",
    "mdl2.fit([u,z1],u,epochs=2,batch_size=batch_size)\n",
    "z2 = encoder2.predict(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = input_img = [Input(shape=(Nx[0],Nx[1],Nu))]\n",
    "input_img.extend([Input(shape=1)])\n",
    "print(input_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder3 = model.Encoder(Nx=Nx,Nu=Nu,features_layers=features_layers,latent_dim=1,filter_window=filter_window,act_fct=act_fct,batch_norm=batch_norm,drop_rate=drop_rate,lmb=lmb)\n",
    "layer_size3 = encoder3.get_layer_shape()\n",
    "\n",
    "new_dim = np.sum([1,1],dtype=np.dtype('int'))+1\n",
    "print(new_dim)\n",
    "\n",
    "x = encoder3(input_img[0])\n",
    "new_x = input_img[1::]\n",
    "new_x.extend([x])\n",
    "print(type(new_x))\n",
    "x = Concatenate(name='stack')(new_x)\n",
    "print(x)\n",
    "\n",
    "x_final = model.Decoder(Nx,Nu,layer_size,features_layers=features_layers,latent_dim=new_dim,filter_window=filter_window,act_fct=act_fct,batch_norm=batch_norm,drop_rate=drop_rate,lmb=lmb)(x)\n",
    "mdl2 = Model(input_img,x_final)\n",
    "print(mdl2.summary())\n",
    "mdl2.compile(optimizer=Adam(learning_rate=0.001),loss='mse')\n",
    "mdl2.fit([u,z1],u,epochs=2,batch_size=batch_size)\n",
    "z2 = encoder2.predict(u)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6df908de1f4850b5dcb2ce91888b76129a7e151e6ab8f38caf16f5b794c79bc1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
