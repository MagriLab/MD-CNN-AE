{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the latent space of nonlinear autoencoders with an unsteady laminar wake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib\n",
    "matplotlib.rcParams['image.cmap']='jet'\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from numpy import einsum\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from MD_AE_tools.mode_decomposition import POD\n",
    "from MD_AE_tools.models.models_no_bias import Autoencoder, Decoder\n",
    "from project_specific_utils import my_discrete_cmap, my_continuous_cmap\n",
    "new_grey = '#C0C0C0'\n",
    "z_colour = (my_discrete_cmap(0),my_discrete_cmap(2),my_discrete_cmap(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up system\n",
    "Please change the parameters in this section to fit your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path to data and model weights\n",
    "datapath = Path('./data/cylinder/ux.h5')\n",
    "path_trained_model_weights = Path('./_weights/weights_ae2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU set-up, ignore if no GPUs are available\n",
    "system_gpu_number = 0 # which gpu to use \n",
    "system_gpu_memory = 2048 # how much gpu memory to allocate this notebook in MB\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[system_gpu_number], 'GPU')# use [] for cpu only, gpus[i] for the ith gpu\n",
    "        tf.config.set_logical_device_configuration(gpus[system_gpu_number],[tf.config.LogicalDeviceConfiguration(memory_limit=system_gpu_memory)]) # set hard memory limit\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Loading and pre-process the laminar wake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(datapath,'r') as hf:\n",
    "    ux_complete = np.array(hf.get('ux'))\n",
    "(nt,_,nx2) = ux_complete.shape\n",
    "dt = 0.0002*625 # Time elapsed between snapshots = dt used in CFD (0.0002) * steps between saving each snapshot (625)\n",
    "freq_main = 0.23 # Hz\n",
    "realt = np.arange(nt)*dt\n",
    "realt_as_period = realt/(1/freq_main)\n",
    "\n",
    "## Plot the entire flow field\n",
    "fig = plt.figure(figsize=(7,4.5))\n",
    "fig.suptitle('Fig1: The complete flow field over a period.')\n",
    "grid = ImageGrid(fig,(0.05,0.0,0.83,0.95),(1,4),cbar_mode='single',share_all=True)\n",
    "for i, ax in enumerate(grid.axes_all):\n",
    "    im = ax.imshow(ux_complete[i*8,:,:],'jet')\n",
    "    ax.set(xticks=[],yticks=[],title=f'${realt_as_period[i*8]:.2f}$'+'$T^{lam}$',ylabel='$x_1$',xlabel='$x_2$',aspect=12/20)\n",
    "    circle = matplotlib.patches.Ellipse((64.5,128.25),26,42,facecolor='white',edgecolor='none')\n",
    "    domain = matplotlib.patches.Rectangle((0,150),129,200,linewidth=1,edgecolor='grey',facecolor='none',linestyle='--')\n",
    "    ax.add_patch(domain)\n",
    "    ax.add_patch(circle)\n",
    "grid.cbar_axes[0].colorbar(im,label='$u_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the data\n",
    "Two steps are necessary:\n",
    "1. Only a part of the near wake is considered, shown as the area inside the dashed lines in Fig1. \n",
    "2. Perform POD. The POD modes modes of the reference data (data modes $\\pmb{\\Phi}$) are needed for comparison and for applying the decoder decomposition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data used for training\n",
    "nx1 = 200 # how many grid points to use in x1 direction.\n",
    "ux = ux_complete[:,150:150+nx1,:].reshape((nt,nx1,nx2))\n",
    "utrain = ux - np.mean(ux,axis=0,keepdims=True)\n",
    "utrain = utrain.reshape((nt,nx1,nx2,1)) # Train on fluctuating velocity\n",
    "\n",
    "## Decompose with POD\n",
    "pod_data = POD(einsum('t x y -> x y t',np.squeeze(ux)),keep_shape=True)\n",
    "modes,lam = pod_data.get_modes\n",
    "a_data = pod_data.Q.T @ modes.reshape((-1,800))\n",
    "\n",
    "## Compute frequency\n",
    "fftfreq = np.fft.fftfreq(800,0.0002*625)\n",
    "freq_data = einsum('t x y -> t',np.abs(np.fft.fft(ux-np.mean(ux,axis=0),axis=0)))\n",
    "freq_data = freq_data / np.std(freq_data)\n",
    "freq_a_data = np.abs(np.fft.fft(a_data-np.mean(a_data,axis=0),axis=0))\n",
    "freq_a_data = freq_a_data / np.std(freq_a_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot summary of the reference data\n",
    "fig = plt.figure(figsize=(9,3))\n",
    "fig.suptitle('Fig2: reference data and POD modes')\n",
    "grid = ImageGrid(fig, 111, (1,5), share_all=True, cbar_mode='each', axes_pad=0.5, cbar_pad=0)\n",
    "im = grid.axes_all[0].imshow(ux[0,:,:])\n",
    "grid.axes_all[0].set_title('Reference data')\n",
    "grid.cbar_axes[0].colorbar(im)\n",
    "for i, (ax,cax) in enumerate(zip(grid.axes_all[1:],grid.cbar_axes[1:])):\n",
    "    im = ax.imshow(modes[...,i])\n",
    "    ax.set(xticks=[],yticks=[],title=f'Data mode {i+1}')\n",
    "    cax.colorbar(im)\n",
    "\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(9,3.5))\n",
    "fig.suptitle('Fig3: POD of data summary')\n",
    "fig.tight_layout()\n",
    "axes[0].bar(range(1,7),100*lam[:6]/np.sum(lam),color=my_discrete_cmap(0))\n",
    "axes[0].set(xticks=[1,2,3,4,5,6],xlabel='Data mode $\\Phi^{lam}$',ylabel='Energy (%)')\n",
    "axes[1].scatter(a_data[:,0],a_data[:,1],color=my_discrete_cmap(0))\n",
    "axes[1].set_ylabel('$A^{lam}_{2,:}$',labelpad=-0.5)\n",
    "axes[1].set_xlabel('$A^{lam}_{1,:}$')\n",
    "plt.subplots_adjust(bottom=0.19)\n",
    "axes[2].plot(fftfreq[:400],(freq_data*2)[:400],color=new_grey,linewidth=5,label='data')\n",
    "for i in [0,2,4,6]:\n",
    "    axes[2].plot(fftfreq[:400],(freq_a_data[:,i]*2)[:400],'--',label='$A_{'+str(i+1)+',:}$/$\\sigma_{'+str(i+1)+'}$',color=my_continuous_cmap(i/6))\n",
    "axes[2].set_xlabel('$St$')\n",
    "axes[2].set_ylabel('Magnitude')\n",
    "axes[2].grid(axis='x')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an autoencoder\n",
    "In this section, we look at a nonlinear autoencoder (AE) with two latent variables trained on the laminar wake. The model is a convolution autoencoder with no bias.\n",
    "The bias terms are no used because we train the AE on the fluctuating velocity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model parameters and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config\n",
    "features_layers = [8, 16, 32] # Number of channels for each convolution layer\n",
    "latent_dim = 2 # latent dimension\n",
    "act_fct = 'tanh' # activation function\n",
    "filter_window= (3,3)\n",
    "\n",
    "# training config \n",
    "nb_epochs = 3000 # Number of epochs\n",
    "batch_size = 100\n",
    "learning_rate = 0.001 \n",
    "\n",
    "nu = 1 # Data has only one velocity component\n",
    "flow_grid = [nx1, nx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = Autoencoder(\n",
    "    flow_grid,\n",
    "    nu,\n",
    "    features_layers=features_layers,\n",
    "    latent_dim=latent_dim,\n",
    "    filter_window=filter_window,\n",
    "    act_fct=act_fct,\n",
    ")\n",
    "ae.compile(optimizer=Adam(learning_rate=learning_rate),loss='mse')\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n",
    "There are two options here. Please run only one of the options.\n",
    "1. load the provided weights from a trained autoencoder. This will produce identical results to the paper.\n",
    "2. Train and autoencoder from scratch. This takes about 15mins on a NVIDIA RTX8000 GPU. This will provide you with similar results to the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 1: Load a trained model \n",
    "ae.evaluate(utrain, utrain, verbose=0)\n",
    "ae.load_weights(path_trained_model_weights)\n",
    "train_model_loss = ae.evaluate(utrain, utrain, verbose=0)\n",
    "print(f'The trained model has loss (MSE {train_model_loss})')\n",
    "\n",
    "## Option 2: Train a new model\n",
    "# loss_ae = []\n",
    "# tempfn_ae = './temp_weights.h5'\n",
    "# model_cb = ModelCheckpoint(tempfn_ae, monitor='loss', save_best_only=True,verbose=0, save_weights_only=True)\n",
    "# cb = [model_cb]\n",
    "# histae = ae.fit(\n",
    "#     utrain, \n",
    "#     utrain,\n",
    "#     epochs=nb_epochs,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=True,\n",
    "#     callbacks=cb,\n",
    "#     verbose=2\n",
    "# )\n",
    "# loss_ae.extend(histae.history['loss'])\n",
    "# ae.load_weights(tempfn_ae) # loading the weight weights\n",
    "# plt.figure()\n",
    "# plt.semilogy(loss_ae)\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('MSE')\n",
    "# plt.show()\n",
    "# print(f'Average loss of the last 100 epochs: {np.mean(loss_ae[-100:])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get output of the AE\n",
    "z_ae = ae.encoder.predict(utrain)\n",
    "ae_pred = np.squeeze(ae.predict(utrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We relate the data modes with the latent variables via decoder decomposition. \n",
    "\n",
    "We define the decoder coefficients $\\pmb{B}$ so that the output of the AE $\\hat{\\pmb{Y}} = \\pmb{\\Phi}\\pmb{B}$. \n",
    "Meaning that $\\frac{d\\hat{\\pmb{Y}}}{d\\pmb{Z}}=\\pmb{\\Phi}\\frac{d\\pmb{B}}{d\\pmb{Z}}$.\n",
    "\n",
    "\n",
    "We can then compute the average absolute rate of change $\\epsilon_{i,j}$, which tells us the relative importance of $\\pmb{B}_{j,:}$ due to the latent variable $\\pmb{Z}_{i,:}$.\n",
    "\n",
    "**\n",
    "$\\epsilon_{i,j} = \\frac{\n",
    "        \\int | \\frac{dB_{j,:}}{dZ_{i,:}}| dZ_{1,:}\\dots dZ_{N_z,:}\n",
    "    }{\n",
    "        \\int dZ_{1,:}\\dots dZ_{N_z,:}\n",
    "}$\n",
    "**\n",
    "\n",
    "Practically, we compute $\\frac{d\\hat{\\pmb{Y}}}{d\\pmb{Z}}$ first using the function ```local_partial_derivative```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_z = np.abs(np.fft.fft(z_ae-np.mean(z_ae,axis=0),axis=0))\n",
    "freq_z = freq_z / np.std(freq_z,0)\n",
    "\n",
    "fig, (ax0,ax1,ax2) = plt.subplots(1,3,figsize=(9,3))\n",
    "fig.suptitle('Fig4: The latent space')\n",
    "fig.tight_layout()\n",
    "ax0.scatter(z_ae[:,0],z_ae[:,1],s=1,color=my_discrete_cmap(0))\n",
    "ax0.set(aspect='equal',xlabel='$Z_{1,:}$',ylabel='$Z_{2,:}$')\n",
    "ax1.plot(realt,z_ae[:,0],label='$Z_{1,:}$',color=my_discrete_cmap(0))\n",
    "ax1.plot(realt,z_ae[:,1],label='$Z_{2,:}$',color=my_discrete_cmap(2))\n",
    "ax1.set(xlabel='t',ylabel='Value',xlim=[0,10])\n",
    "ax1.legend()\n",
    "ax2.plot(fftfreq[:400],(freq_data*2)[:400],c=new_grey,linewidth=5,label='data')\n",
    "for i in range(latent_dim):\n",
    "    ax2.plot(fftfreq[:400],(freq_z[:,i]*2)[:400],'--',label='$'+'Z_{'+str({i+1})+',:}$/$\\sigma_{'+str(i+1)+'}$',color=z_colour[i])\n",
    "ax2.set(ylabel='Magnitude', xlabel='St')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_partial_derivative(decoder:Decoder, z: np.array, h:float, batch_size:int):\n",
    "    \"\"\"Compute dy/dz of a trained decoder.\n",
    "    \n",
    "    -----------------\n",
    "    Input:\n",
    "    - decoder: a trained decoder. For example ae.decoder\n",
    "    - z: the latent vector, output of an encoder, with shape (nt,nz)\n",
    "    - h: step size, used to calculate derivatives\n",
    "    - batch size: the batch size to pass into decoder.predict\n",
    "    \"\"\"\n",
    "\n",
    "    (nt,nz) = z.shape\n",
    "    (_,_nx,_ny,_nu) = decoder.predict(z[[0],:]).shape\n",
    "    n = _nx*_ny*_nu\n",
    "\n",
    "    dydz = np.zeros((nz,nt,n))\n",
    "\n",
    "    for i in range(nz):\n",
    "\n",
    "        hi = np.zeros((1,nz))\n",
    "        hi[0,i] = h #[1,Nz]\n",
    "\n",
    "        z_left = z + hi\n",
    "        z_right = z - hi\n",
    "\n",
    "        f_z_left = decoder.predict(z_left, batch_size=batch_size).reshape((nt,n))\n",
    "        f_z_right = decoder.predict(z_right, batch_size=batch_size).reshape((nt,n))\n",
    "        dydz_i = (f_z_left - f_z_right) / (2*h) #[Nt,N]\n",
    "\n",
    "        dydz[i,:,:] = dydz_i\n",
    "    \n",
    "    return dydz.reshape((nz,nt,_nx,_ny,nu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dydz = local_partial_derivative(ae.decoder,z_ae,0.001,batch_size)[...,0]\n",
    "dbdz = jnp.einsum('z t x y, x y m -> z t m', dydz, modes)\n",
    "avgbz = jnp.mean(jnp.abs(dbdz),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "ax.bar(np.arange(1,7)-0.15,avgbz[0,:6],width=0.3,label='$Z_{1,:}$',color=z_colour[0])\n",
    "ax.bar(np.arange(1,7)+0.15,avgbz[1,:6],width=0.3,label='$Z_{2,:}$',color=z_colour[1])\n",
    "ax.set(yticks=[], xticklabels=np.arange(0,7))\n",
    "ax.set_ylabel(ylabel='$\\epsilon_{i,j}$',fontsize='large')\n",
    "ax.set_xlabel(xlabel='Data mode $j$',fontsize='large')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.title('Fig5: Averge absolute rate of change')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all valid values on a contour plot.\n",
    "\n",
    "This produces contour plots for the first four decoder coefficients for all values of the latent variables between -1 and 1. The grey circle on the plots are the observed latent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_b_hold_z1_constant(y_i,modes):\n",
    "    b_i = jnp.einsum('t x y, x y m -> t m', jnp.squeeze(y_i),modes)\n",
    "    return b_i\n",
    "\n",
    "z1 = np.linspace(-0.99,0.99,101).astype('float32')\n",
    "z2 = np.linspace(-0.99,0.99,101).astype('float32')\n",
    "idx_z2_0 = np.squeeze(np.argwhere(np.abs(z2-0)<1.19209e-07))\n",
    "idx_z1_0 = np.squeeze(np.argwhere(np.abs(z1-0)<1.19209e-07))\n",
    "zx,zy = np.meshgrid(z1,z2)\n",
    "_y_grid =[]\n",
    "for i in range(len(z1)):\n",
    "    y_i = ae.decoder.predict(\n",
    "        tf.stack((zx[:,i],zy[:,0]),axis=1)\n",
    "    )\n",
    "    _y_grid.append(y_i)\n",
    "_y_grid = np.array(_y_grid)\n",
    "\n",
    "v_get_b_gridded = jax.vmap(get_b_hold_z1_constant,in_axes=(0,None))\n",
    "ae_b_post_gridded = v_get_b_gridded(_y_grid,modes[...,:6]) #[z1,z2,modes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2,figsize=(7,7),sharex=True,sharey=True)\n",
    "fig.suptitle('Fig6: Decoder cofficients for all valid values of the latent variables.')\n",
    "ax_flat = ax.flatten()\n",
    "for i in range(4):\n",
    "    cs = ax_flat[i].contour(zx,zy,ae_b_post_gridded[:,:,i].T,levels=20,zorder=5)\n",
    "    ax_flat[i].clabel(cs)\n",
    "    ax_flat[i].grid()\n",
    "    ax_flat[i].scatter(z_ae[:,0],z_ae[:,1],zorder=1,c=new_grey,alpha=0.5)\n",
    "    ax_flat[i].set_aspect('equal')\n",
    "ax_flat[2].set(xlabel='$Z_{1,:}$',ylabel='$Z_{2,:}$')\n",
    "ax_flat[0].set(ylabel='$Z_{2,:}$')\n",
    "ax_flat[3].set(xlabel='$Z_{1,:}$')\n",
    "ax_flat[0].set_title('$B_{1,:}$',fontsize='large')\n",
    "ax_flat[1].set_title('$B_{2,:}$',fontsize='large')\n",
    "ax_flat[2].set_title('$B_{3,:}$',fontsize='large')\n",
    "ax_flat[3].set_title('$B_{4,:}$',fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different latent dimension\n",
    "\n",
    "The dimension of the latent space has a significant impact on the interpretation of the latent variables. \n",
    "Here shows an example where the latent dimension is $1$ (too small). \n",
    "Because the reference data contains periodocity, which cannot be expressed in AE with one latent variable, the latent variable are force to take up higher, unphysical frequency to achieve numerical approximation.\n",
    "\n",
    "You can also play around with the latent dimension to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config\n",
    "latent_dim1 = 1 # latent dimension\n",
    "nb_epochs1 = 3000 # Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1 = Autoencoder(\n",
    "    flow_grid,\n",
    "    nu,\n",
    "    features_layers=features_layers,\n",
    "    latent_dim=latent_dim1,\n",
    "    filter_window=filter_window,\n",
    "    act_fct=act_fct,\n",
    ")\n",
    "ae1.compile(optimizer=Adam(learning_rate=learning_rate),loss='mse')\n",
    "ae1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 1: Load a trained model \n",
    "ae1.evaluate(utrain, utrain, verbose=0)\n",
    "ae1.load_weights('_weights/weights_ae1.h5')\n",
    "train_model_loss = ae1.evaluate(utrain, utrain, verbose=0)\n",
    "print(f'The trained model has loss (MSE {train_model_loss})')\n",
    "\n",
    "# # Option 2: Train a new model\n",
    "# loss_ae1 = []\n",
    "# tempfn_ae1 = './temp_weights1.h5'\n",
    "# model_cb = ModelCheckpoint(tempfn_ae1, monitor='loss', save_best_only=True,verbose=0, save_weights_only=True)\n",
    "# cb = [model_cb]\n",
    "# histae1 = ae1.fit(\n",
    "#     utrain, \n",
    "#     utrain,\n",
    "#     epochs=nb_epochs1,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=True,\n",
    "#     callbacks=cb,\n",
    "#     verbose=2\n",
    "# )\n",
    "# loss_ae1.extend(histae1.history['loss'])\n",
    "# ae1.load_weights(tempfn_ae1) # loading the weight weights\n",
    "# plt.figure()\n",
    "# plt.semilogy(loss_ae1)\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('MSE')\n",
    "# plt.show()\n",
    "# print(f'Average loss of the last 100 epochs: {np.mean(loss_ae1[-100:])}')\n",
    "\n",
    "## Get output of the AE\n",
    "z_ae1 = ae1.encoder.predict(utrain)\n",
    "ae_pred1 = np.squeeze(ae1.predict(utrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_z1 = np.abs(np.fft.fft(z_ae1-np.mean(z_ae1,axis=0),axis=0))\n",
    "freq_z1 = freq_z1 / np.std(freq_z1,0)\n",
    "\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(6,3))\n",
    "fig.suptitle('The latent space of AE with one latent variable')\n",
    "fig.tight_layout()\n",
    "for i in range(latent_dim1):\n",
    "    ax0.plot(realt,z_ae1[:,0],label='$Z_{'+str(i+1)+',:}$',color=my_continuous_cmap(i/latent_dim1))\n",
    "ax0.set(xlabel='t',ylabel='Value',xlim=[0,20])\n",
    "ax0.legend()\n",
    "ax1.plot(fftfreq[:400],(freq_data*2)[:400],c=new_grey,linewidth=5,label='data')\n",
    "for i in range(latent_dim1):\n",
    "    ax1.plot(fftfreq[:400],(freq_z1[:,i]*2)[:400],'--',label='$'+'Z_{'+str({i+1})+',:}$/$\\sigma_{'+str(i+1)+'}$',color=z_colour[i])\n",
    "ax1.set(ylabel='Magnitude', xlabel='St')\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MD-CNN-AE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
